{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:46:18.792066Z",
     "start_time": "2025-01-21T06:46:17.249755Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:36:20.531671Z",
     "iopub.status.busy": "2025-01-21T07:36:20.531470Z",
     "iopub.status.idle": "2025-01-21T07:36:22.248633Z",
     "shell.execute_reply": "2025-01-21T07:36:22.248030Z",
     "shell.execute_reply.started": "2025-01-21T07:36:20.531655Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:46:18.795700Z",
     "start_time": "2025-01-21T06:46:18.793686Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:36:22.249179Z",
     "iopub.status.busy": "2025-01-21T07:36:22.248981Z",
     "iopub.status.idle": "2025-01-21T07:36:22.251607Z",
     "shell.execute_reply": "2025-01-21T07:36:22.251046Z",
     "shell.execute_reply.started": "2025-01-21T07:36:22.249170Z"
    }
   },
   "outputs": [],
   "source": [
    "Data_path=\"./Datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape images in ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:46:19.574715Z",
     "start_time": "2025-01-21T06:46:19.400153Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:36:23.908874Z",
     "iopub.status.busy": "2025-01-21T07:36:23.908741Z",
     "iopub.status.idle": "2025-01-21T07:36:24.078558Z",
     "shell.execute_reply": "2025-01-21T07:36:24.078170Z",
     "shell.execute_reply.started": "2025-01-21T07:36:23.908865Z"
    }
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "\n",
    "x_train = X_train.reshape(60000, 784)\n",
    "x_test = X_test.reshape(10000, 784)\n",
    "\n",
    "print(\"X_train new shape\", x_train.shape)\n",
    "print(\"X_test new shape\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:46:28.251269Z",
     "start_time": "2025-01-21T06:46:20.428242Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:36:24.419313Z",
     "iopub.status.busy": "2025-01-21T07:36:24.419173Z",
     "iopub.status.idle": "2025-01-21T07:36:28.529613Z",
     "shell.execute_reply": "2025-01-21T07:36:28.529222Z",
     "shell.execute_reply.started": "2025-01-21T07:36:24.419304Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "## Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(layers.Dense(20, activation='sigmoid'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:46:33.179201Z",
     "start_time": "2025-01-21T06:46:33.004755Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:36:28.530440Z",
     "iopub.status.busy": "2025-01-21T07:36:28.530271Z",
     "iopub.status.idle": "2025-01-21T07:36:28.766635Z",
     "shell.execute_reply": "2025-01-21T07:36:28.766217Z",
     "shell.execute_reply.started": "2025-01-21T07:36:28.530425Z"
    }
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:46:34.563274Z",
     "start_time": "2025-01-21T06:46:34.286416Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:36:30.889793Z",
     "iopub.status.busy": "2025-01-21T07:36:30.888958Z",
     "iopub.status.idle": "2025-01-21T07:36:31.466920Z",
     "shell.execute_reply": "2025-01-21T07:36:31.466245Z",
     "shell.execute_reply.started": "2025-01-21T07:36:30.889771Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot 4 images as gray scale\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[6], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[7], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[9], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random kernel_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:46:40.848835Z",
     "start_time": "2025-01-21T06:46:40.496551Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:36:32.811804Z",
     "iopub.status.busy": "2025-01-21T07:36:32.811432Z",
     "iopub.status.idle": "2025-01-21T07:36:33.350475Z",
     "shell.execute_reply": "2025-01-21T07:36:33.349577Z",
     "shell.execute_reply.started": "2025-01-21T07:36:32.811788Z"
    }
   },
   "outputs": [],
   "source": [
    "#i=int(np.random.rand(1,1)*60000)\n",
    "#634 #924 #952 #3611  #4458\n",
    "import numpy as np\n",
    "x=X_train[3611]\n",
    "\n",
    "\n",
    "print(\"Actual Image\")\n",
    "plt.imshow(x, cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Random Weights Kennel\")\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=1,\n",
    "                 kernel_size=7,\n",
    "                 input_shape=(28,28,1),\n",
    "                 kernel_initializer='random_uniform'))\n",
    "\n",
    "img_reshape=np.expand_dims(x, axis=0)\n",
    "img_reshape=np.expand_dims(img_reshape, axis=3)\n",
    "img_reshape=model.predict(img_reshape)\n",
    "pixels = np.matrix(img_reshape[:][:][:][0])\n",
    "plt.imshow(pixels,cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant kernel_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:46:43.543673Z",
     "start_time": "2025-01-21T06:46:43.537309Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:36:34.039735Z",
     "iopub.status.busy": "2025-01-21T07:36:34.039520Z",
     "iopub.status.idle": "2025-01-21T07:36:34.045051Z",
     "shell.execute_reply": "2025-01-21T07:36:34.044412Z",
     "shell.execute_reply.started": "2025-01-21T07:36:34.039720Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "filter1=np.array([[1,1,1,1,1,1,1],\n",
    "           [1,1,1,1,1,1,1],\n",
    "           [100,100,100,100,100,100,100],\n",
    "           [100,100,100,100,100,100,100],\n",
    "           [100,100,100,100,100,100,100],\n",
    "           [1,1,1,1,1,1,1],\n",
    "           [1,1,1,1,1,1,1]])\n",
    "print(\"filter1 \\n\", filter1)\n",
    "\n",
    "filter2=np.transpose(filter1)\n",
    "print(\"filter2 \\n\",filter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:46:44.622218Z",
     "start_time": "2025-01-21T06:46:44.259907Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:38:24.350398Z",
     "iopub.status.busy": "2025-01-21T07:38:24.350026Z",
     "iopub.status.idle": "2025-01-21T07:38:24.515513Z",
     "shell.execute_reply": "2025-01-21T07:38:24.514911Z",
     "shell.execute_reply.started": "2025-01-21T07:38:24.350372Z"
    }
   },
   "outputs": [],
   "source": [
    "#Try #634 #924 #952 #3611  #4458\n",
    "x=X_train[634]\n",
    "\n",
    "print(\"Actual Image\")\n",
    "plt.imshow(x, cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "\n",
    "print(\"Horizontal Line\")\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(1,\n",
    "                 kernel_size=7,\n",
    "                 input_shape=(28,28,1),\n",
    "                 kernel_initializer=keras.initializers.Constant(filter1)))\n",
    "\n",
    "img_reshape=np.expand_dims(x, axis=0)\n",
    "img_reshape=np.expand_dims(img_reshape, axis=3)\n",
    "img_reshape=model.predict(img_reshape)\n",
    "pixels = np.matrix(img_reshape[:][:][:][0])\n",
    "plt.imshow(pixels,cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "\n",
    "print(\"Vertical Line\")\n",
    "model=Sequential()\n",
    "model.add(Conv2D(1,\n",
    "                 kernel_size=7,\n",
    "                 input_shape=(28,28,1),\n",
    "                 kernel_initializer=keras.initializers.Constant(filter2)))\n",
    "\n",
    "img_reshape=np.expand_dims(x, axis=0)\n",
    "img_reshape=np.expand_dims(img_reshape, axis=3)\n",
    "img_reshape=model.predict(img_reshape)\n",
    "pixels = np.matrix(img_reshape[:][:][:][0])\n",
    "plt.imshow(pixels,cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filters for Colour Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:46:49.659608Z",
     "start_time": "2025-01-21T06:46:49.564563Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:38:46.348724Z",
     "iopub.status.busy": "2025-01-21T07:38:46.348511Z",
     "iopub.status.idle": "2025-01-21T07:38:46.422599Z",
     "shell.execute_reply": "2025-01-21T07:38:46.421982Z",
     "shell.execute_reply.started": "2025-01-21T07:38:46.348708Z"
    }
   },
   "outputs": [],
   "source": [
    "i=int(np.random.rand(1,1)*60000)\n",
    "print(i)\n",
    "\n",
    "imp_path=Data_path+\"43534.png\"\n",
    "print(\"imp_path\",imp_path)\n",
    "\n",
    "%matplotlib inline\n",
    "x=plt.imread(imp_path)\n",
    "print(x.shape)\n",
    "y=x[10:15,10:15]\n",
    "print(y*20)\n",
    "print(y.shape)\n",
    "plt.imshow((y*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:46:54.322043Z",
     "start_time": "2025-01-21T06:46:53.964749Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:38:47.884963Z",
     "iopub.status.busy": "2025-01-21T07:38:47.884741Z",
     "iopub.status.idle": "2025-01-21T07:38:48.476062Z",
     "shell.execute_reply": "2025-01-21T07:38:48.475451Z",
     "shell.execute_reply.started": "2025-01-21T07:38:47.884947Z"
    }
   },
   "outputs": [],
   "source": [
    "#i=int(np.random.rand(1,1)*60000)\n",
    "#634 #924 #952 #3611  #4458\n",
    "import numpy as np\n",
    "x=X_train[3611]\n",
    "\n",
    "print(\"Actual Image Shape \" ,  x.shape)\n",
    "plt.imshow(x, cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Random Weights Kennel siz3 7X7\")\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=1,\n",
    "                 kernel_size=7,\n",
    "                 input_shape=(28,28,1),\n",
    "                 kernel_initializer='random_uniform'))\n",
    "\n",
    "img_reshape=np.expand_dims(x, axis=0)\n",
    "img_reshape=np.expand_dims(img_reshape, axis=3)\n",
    "img_reshape=model.predict(img_reshape)\n",
    "pixels = np.matrix(img_reshape[:][:][:][0])\n",
    "print(\"Output Shape \" ,pixels.shape)\n",
    "plt.imshow(pixels,cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Random Weights Kennel siz3 5X5\")\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=1,\n",
    "                 kernel_size=5,\n",
    "                 input_shape=(28,28,1),\n",
    "                 kernel_initializer='random_uniform'))\n",
    "\n",
    "img_reshape=np.expand_dims(x, axis=0)\n",
    "img_reshape=np.expand_dims(img_reshape, axis=3)\n",
    "img_reshape=model.predict(img_reshape)\n",
    "pixels = np.matrix(img_reshape[:][:][:][0])\n",
    "print(\"Output Shape \" ,pixels.shape)\n",
    "plt.imshow(pixels,cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN for CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:48:53.500421Z",
     "start_time": "2025-01-21T06:48:53.497894Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:38:49.929488Z",
     "iopub.status.busy": "2025-01-21T07:38:49.929266Z",
     "iopub.status.idle": "2025-01-21T07:38:49.933359Z",
     "shell.execute_reply": "2025-01-21T07:38:49.932521Z",
     "shell.execute_reply.started": "2025-01-21T07:38:49.929472Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:49:27.585282Z",
     "start_time": "2025-01-21T06:48:54.766746Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:38:50.646714Z",
     "iopub.status.busy": "2025-01-21T07:38:50.646464Z",
     "iopub.status.idle": "2025-01-21T07:38:53.086473Z",
     "shell.execute_reply": "2025-01-21T07:38:53.085613Z",
     "shell.execute_reply.started": "2025-01-21T07:38:50.646698Z"
    }
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:49:28.463840Z",
     "start_time": "2025-01-21T06:49:28.460477Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:38:55.557683Z",
     "iopub.status.busy": "2025-01-21T07:38:55.557474Z",
     "iopub.status.idle": "2025-01-21T07:38:55.561475Z",
     "shell.execute_reply": "2025-01-21T07:38:55.560876Z",
     "shell.execute_reply.started": "2025-01-21T07:38:55.557668Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "print(\"y_test.shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:49:29.860796Z",
     "start_time": "2025-01-21T06:49:29.387797Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:38:56.273979Z",
     "iopub.status.busy": "2025-01-21T07:38:56.273771Z",
     "iopub.status.idle": "2025-01-21T07:38:56.536851Z",
     "shell.execute_reply": "2025-01-21T07:38:56.536390Z",
     "shell.execute_reply.started": "2025-01-21T07:38:56.273965Z"
    }
   },
   "outputs": [],
   "source": [
    "#Drawing Few images\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[y_train[i][0]])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:49:30.853412Z",
     "start_time": "2025-01-21T06:49:30.764264Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:38:57.502020Z",
     "iopub.status.busy": "2025-01-21T07:38:57.501802Z",
     "iopub.status.idle": "2025-01-21T07:38:57.568253Z",
     "shell.execute_reply": "2025-01-21T07:38:57.567834Z",
     "shell.execute_reply.started": "2025-01-21T07:38:57.502005Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:51:38.750651Z",
     "start_time": "2025-01-21T06:49:34.107830Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:38:58.730767Z",
     "iopub.status.busy": "2025-01-21T07:38:58.730558Z",
     "iopub.status.idle": "2025-01-21T07:39:48.010233Z",
     "shell.execute_reply": "2025-01-21T07:39:48.009827Z",
     "shell.execute_reply.started": "2025-01-21T07:38:58.730752Z"
    }
   },
   "outputs": [],
   "source": [
    "import time #To measure the execution time \n",
    "start = time.time()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.1),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=16,\n",
    "          epochs=12, \n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time is\", int(end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study- Sign Language Reading from Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:53:20.092253Z",
     "start_time": "2025-01-21T06:53:19.914015Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:40:46.891515Z",
     "iopub.status.busy": "2025-01-21T07:40:46.891285Z",
     "iopub.status.idle": "2025-01-21T07:40:46.904956Z",
     "shell.execute_reply": "2025-01-21T07:40:46.904356Z",
     "shell.execute_reply.started": "2025-01-21T07:40:46.891499Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let us keep all the libraries ready\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D,  Activation\n",
    "from tensorflow.keras.layers import Reshape, Input, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Convolution2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import regularizers, initializers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow, imsave\n",
    "import imageio\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:55:53.779924Z",
     "start_time": "2025-01-21T06:55:53.532436Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:40:48.238793Z",
     "iopub.status.busy": "2025-01-21T07:40:48.238582Z",
     "iopub.status.idle": "2025-01-21T07:40:48.513705Z",
     "shell.execute_reply": "2025-01-21T07:40:48.513129Z",
     "shell.execute_reply.started": "2025-01-21T07:40:48.238778Z"
    }
   },
   "outputs": [],
   "source": [
    "#Few random Images\n",
    "fig, ax = plt.subplots(2,2)\n",
    "location=Data_path+'Sign_Language_Digits/Sign-Language-Digits-Dataset-master/Dataset/'\n",
    "i=random.randint(0, 9)\n",
    "img_id=18+i\n",
    "img=imageio.imread(location+str(i)+\"/IMG_11\"+str(img_id)+\".JPG\")\n",
    "ax[0,0].imshow(img)\n",
    "\n",
    "i=random.randint(0, 9)\n",
    "img_id=18+i\n",
    "img=imageio.imread(location+str(i)+\"/IMG_11\"+str(img_id)+\".JPG\")\n",
    "ax[0,1].imshow(img)\n",
    "\n",
    "i=random.randint(0, 9)\n",
    "img_id=18+i\n",
    "img=imageio.imread(location+str(i)+\"/IMG_11\"+str(img_id)+\".JPG\")\n",
    "ax[1,0].imshow(img)\n",
    "\n",
    "i=random.randint(0, 9)\n",
    "img_id=18+i\n",
    "img=imageio.imread(location+str(i)+\"/IMG_11\"+str(img_id)+\".JPG\")\n",
    "ax[1,1].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:56:12.322647Z",
     "start_time": "2025-01-21T06:56:12.216431Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:40:52.521885Z",
     "iopub.status.busy": "2025-01-21T07:40:52.521674Z",
     "iopub.status.idle": "2025-01-21T07:40:52.593251Z",
     "shell.execute_reply": "2025-01-21T07:40:52.592830Z",
     "shell.execute_reply.started": "2025-01-21T07:40:52.521870Z"
    }
   },
   "outputs": [],
   "source": [
    "########################\n",
    "# Generators\n",
    "########################\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 256\n",
    "target_size = (100,100)\n",
    "\n",
    "\n",
    "########################\n",
    "# Data Directory\n",
    "########################\n",
    "\n",
    "data_dir = location  # this is the image datasets directory\n",
    "location_1=Data_path+\"Sign_language_digits_dataset_64_64\\\\\"\n",
    "########################\n",
    "# Data generator : Any preprocessing options/steps can be  defined here\n",
    "########################\n",
    "datagen = ImageDataGenerator(rescale = 1./255,  # scaling the images matrix(standard preprocessing step)\n",
    "                             validation_split=0.2) # set validation split\n",
    "\n",
    "########################\n",
    "# Train generator\n",
    "########################\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=target_size,   # resizing the input images to a specific size\n",
    "    batch_size=batch_size,     # Batch size, iterator will generate a random batch with this size\n",
    "    color_mode = 'grayscale',  # keeping the channel to grayscale for easy calculations\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset=\"training\") \n",
    "\n",
    "########################\n",
    "# Validation generator\n",
    "########################\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir, # same directory as training data\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode = 'grayscale', \n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset=\"validation\") # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:56:13.744122Z",
     "start_time": "2025-01-21T06:56:13.658866Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:40:53.746585Z",
     "iopub.status.busy": "2025-01-21T07:40:53.746361Z",
     "iopub.status.idle": "2025-01-21T07:40:53.831162Z",
     "shell.execute_reply": "2025-01-21T07:40:53.830598Z",
     "shell.execute_reply.started": "2025-01-21T07:40:53.746568Z"
    }
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "# Convolution layer\n",
    "model1.add(Conv2D(64, (3, 3), input_shape = (100, 100, 1), activation = 'relu'))\n",
    "\n",
    "# Pooling layer\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding second convolutional layer\n",
    "model1.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding third convolutional layer\n",
    "model1.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Flattening\n",
    "model1.add(Flatten())\n",
    "\n",
    "# Step 4 - Fully connected dense layers\n",
    "model1.add(Dense(units = 256, activation = 'relu'))\n",
    "model1.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:56:34.302970Z",
     "start_time": "2025-01-21T06:56:14.596730Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:42:28.401956Z",
     "iopub.status.busy": "2025-01-21T07:42:28.401734Z",
     "iopub.status.idle": "2025-01-21T07:42:41.383448Z",
     "shell.execute_reply": "2025-01-21T07:42:41.383109Z",
     "shell.execute_reply.started": "2025-01-21T07:42:28.401940Z"
    }
   },
   "outputs": [],
   "source": [
    "# model1 compilation\n",
    "model1.compile(optimizer =SGD(learning_rate=0.01, momentum = 0.9), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "########################\n",
    "# fit model and train\n",
    "########################\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "model1.fit(\n",
    "        train_generator, \n",
    "        steps_per_epoch = len(train_generator), #total number of batches in one train epoch(train observation/batch size; also called iterations per epoch)\n",
    "        epochs=20,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = len(validation_generator), #total number of batches in validation(validation observation/batch size)\n",
    "        verbose=1)\n",
    "\n",
    "model1.save_weights('m1_Sign_Language_20epochs.weights.h5')\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time is\", int(end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:57:13.826053Z",
     "start_time": "2025-01-21T06:57:11.822267Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:42:55.621954Z",
     "iopub.status.busy": "2025-01-21T07:42:55.621745Z",
     "iopub.status.idle": "2025-01-21T07:42:57.263806Z",
     "shell.execute_reply": "2025-01-21T07:42:57.263444Z",
     "shell.execute_reply.started": "2025-01-21T07:42:55.621939Z"
    }
   },
   "outputs": [],
   "source": [
    "model1.load_weights(Data_path+\"/Pre_trained_models/m1_Sign_Language_20epochs.h5\")\n",
    "\n",
    "model1.fit(\n",
    "        train_generator, \n",
    "        steps_per_epoch = len(train_generator), \n",
    "        epochs=2,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = len(validation_generator), \n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:57:26.022018Z",
     "start_time": "2025-01-21T06:57:24.051277Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T07:43:04.626644Z",
     "iopub.status.busy": "2025-01-21T07:43:04.626437Z",
     "iopub.status.idle": "2025-01-21T07:43:06.164049Z",
     "shell.execute_reply": "2025-01-21T07:43:06.163559Z",
     "shell.execute_reply.started": "2025-01-21T07:43:04.626629Z"
    }
   },
   "outputs": [],
   "source": [
    "model1.load_weights(Data_path+\"/Pre_trained_models/m1_Sign_Language_50epochs.h5\")\n",
    "\n",
    "model1.fit(\n",
    "        train_generator, \n",
    "        steps_per_epoch = len(train_generator), \n",
    "        epochs=2,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = len(validation_generator), \n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model2 - Model with Receptive field "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the image shape to 64X64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:57:33.408273Z",
     "start_time": "2025-01-21T06:57:33.307539Z"
    }
   },
   "outputs": [],
   "source": [
    "########################\n",
    "# Generators\n",
    "########################\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 256\n",
    "target_size = (64,64)\n",
    "\n",
    "\n",
    "########################\n",
    "# Data Directory\n",
    "########################\n",
    "\n",
    "data_dir = location  # this is the image datasets directory\n",
    "\n",
    "########################\n",
    "# Data generator : Any preprocessing options/steps can be  defined here\n",
    "########################\n",
    "datagen = ImageDataGenerator(rescale = 1./255,  # scaling the images matrix(standard preprocessing step)\n",
    "                             validation_split=0.2) # set validation split\n",
    "\n",
    "########################\n",
    "# Train generator\n",
    "########################\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=target_size,   # resizing the input images to a specific size\n",
    "    batch_size=batch_size,     # Batch size, iterator will generate a random batch with this size\n",
    "    color_mode = 'grayscale',  # keeping the channel to grayscale for easy calculations\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset=\"training\") # set as training data\n",
    "\n",
    "########################\n",
    "# Validation generator\n",
    "########################\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir, # same directory as training data\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode = 'grayscale', \n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset=\"validation\") # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:57:34.620809Z",
     "start_time": "2025-01-21T06:57:34.523941Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "# Convolution and Pooling layers\n",
    "model2.add(Conv2D(16, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
    "model2.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model2.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model2.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model2.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "# Flattening and  Fully connected dense layers\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(units = 32, activation = 'relu'))\n",
    "model2.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:58:18.283102Z",
     "start_time": "2025-01-21T06:57:35.320893Z"
    }
   },
   "outputs": [],
   "source": [
    "# model compilation\n",
    "model2.compile(optimizer =SGD(lr=0.01, momentum = 0.9), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "########################\n",
    "# fit model and train\n",
    "########################\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "model2.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = len(train_generator), #total number of batches in one train epoch(train observation/batch size; also called iterations per epoch)\n",
    "        epochs=50,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = len(validation_generator), #total number of batches in validation(validation observation/batch size)\n",
    "        verbose=1)\n",
    "\n",
    "model2.save_weights('m2_Receptive_field_50epochs.h5')\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time is\", int(end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights(Data_path+\"/Pre_trained_models/m2_ Receptive_field_50epochs.h5\")\n",
    "\n",
    "model2.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = len(train_generator), #total number of batches in one train epoch(train observation/batch size; also called iterations per epoch)\n",
    "        epochs=2,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = len(validation_generator), #total number of batches in validation(validation observation/batch size)\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model2 - Model with Dropout and Receptive field "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batchsize Changed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Generators\n",
    "########################\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 64\n",
    "target_size = (64,64)\n",
    "\n",
    "\n",
    "########################\n",
    "# Data Directory\n",
    "########################\n",
    "\n",
    "data_dir = location  # this is the image datasets directory\n",
    "\n",
    "########################\n",
    "# Data generator : Any preprocessing options/steps can be  defined here\n",
    "########################\n",
    "datagen = ImageDataGenerator(rescale = 1./255,  # scaling the images matrix(standard preprocessing step)\n",
    "                             validation_split=0.2) # set validation split\n",
    "\n",
    "########################\n",
    "# Train generator\n",
    "########################\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=target_size,   # resizing the input images to a specific size\n",
    "    batch_size=batch_size,     # Batch size, iterator will generate a random batch with this size\n",
    "    color_mode = 'grayscale',  # keeping the channel to grayscale for easy calculations\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset=\"training\") # set as training data\n",
    "\n",
    "########################\n",
    "# Validation generator\n",
    "########################\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir, # same directory as training data\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode = 'grayscale', \n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset=\"validation\") # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "# Convolution and Pooling layers\n",
    "model2.add(Conv2D(16, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
    "model2.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model2.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model2.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# Flattening and  Fully connected dense layers\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(units = 32, activation = 'relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compilation\n",
    "model2.compile(optimizer =SGD(lr=0.01, momentum = 0.9), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "########################\n",
    "# fit model and train\n",
    "########################\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "history=model2.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = len(train_generator), \n",
    "        epochs=50,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = len(validation_generator), \n",
    "        verbose=1)\n",
    "\n",
    "model2.save_weights('m2_Dropout_Rec_fld_50epochs.h5')\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time is\", int(end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.title(\"Train and Valid Accuracy by Epochs\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0,1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights(Data_path+\"/Pre_trained_models/m2_Dropout_Rec_fld_50epochs.h5\")\n",
    "\n",
    "history=model2.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = len(train_generator), \n",
    "        epochs=2,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = len(validation_generator), \n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights(Data_path+\"/Pre_trained_models/m2_Dropout_Rec_fld_100epochs.h5\")\n",
    "\n",
    "history=model2.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = len(train_generator), \n",
    "        epochs=2,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = len(validation_generator), \n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3, 3), input_shape = (32, 32, 1)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(2, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(3, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model3 with Batch Normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Conv2D(16, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "model3.add(Conv2D(16, (3, 3), activation = 'relu'))\n",
    "model3.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "model3.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model3.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "model3.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model3.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "model3.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(units = 16, activation = 'relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer =SGD(lr=0.03, momentum = 0.9), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "########################\n",
    "# fit model and train\n",
    "########################\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "history=model3.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = len(train_generator), \n",
    "        epochs=200,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = len(validation_generator), \n",
    "        verbose=1)\n",
    "\n",
    "model3.save_weights('m3_BatchNorm_200epochs.h5')\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time is\", int(end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the results \n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.title(\"Train and Valid Accuracy by Epochs\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0,1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.load_weights(Data_path+\"/Pre_trained_models/m3_BatchNorm_200epochs.h5\")\n",
    "\n",
    "history=model3.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = len(train_generator), \n",
    "        epochs=2,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = len(validation_generator), \n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam  Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer =Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "########################\n",
    "# fit model and train\n",
    "########################\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "history=model3.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = len(train_generator), \n",
    "        epochs=100,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = len(validation_generator), \n",
    "        verbose=1)\n",
    "\n",
    "model3.save_weights('m3_BatchNorm_and_Adam_100epochs.h5')\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time is\", int(end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the results \n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.title(\"Train and Valid Accuracy by Epochs\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0,1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.load_weights(Data_path+\"/Pre_trained_models/m3_BatchNorm_and_Adam_100epochs.h5\")\n",
    "\n",
    "history=model3.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = len(train_generator), \n",
    "        epochs=2,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = len(validation_generator), \n",
    "        verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demos",
   "language": "python",
   "name": "demos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
